{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-fashion-mnist-feed-forward-colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jarusgnuj/ai-ml-wksh/blob/master/notebooks/image_classification/1_keras_fashion_mnist_feed_forward_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C12qzqX61ObY",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network with Keras\n",
        "\n",
        "A neural network computation requires a lot of matrix multiplication. It so happens that GPUs are extremely quicker in performing matrix multiplication than CPUs. Python's datastructure like Numpy is great for creating neural networks, but there is not an easy implementation to run numpy codes in a Graphics Processing Unit (GPU). There are many libraries that run processing on GPUs, like Keras, tensorflow, pytorch, torch, etc. All these libraries work on tensors. Tensors are like numpy arrays or matrices but with the added advantage that they can run in both GPUs and CPUs. We will use *Keras* for the rest of the course.\n",
        "\n",
        "In addition to providing GPU support, Keras also has a vast number of modules that help design, train, and test a neural network very easy. For example, we can use its *Sequential* module to create a neural network, without ever having to think about weights or its dimensions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ3UuWRM3V5Q",
        "colab_type": "text"
      },
      "source": [
        "## Image Classification\n",
        "\n",
        "Through this notebook, we will use Keras to implement a neural network architecture that can with high accuracy label an image. We will design a network, then train the network on an image dataset, and finally test it with new unseen data examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPP-aQ7_jCPj",
        "colab_type": "text"
      },
      "source": [
        "# Fashion MNIST Dataset\n",
        "\n",
        "The [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset consists of 28x28 picture grayscale image of a clothing item like t-shirts, jackets, sandals etc. In total, the fashion MNIST dataset consists of 70K images divided into 10 categories. The dataset is large enough for us to use neural networks to accurately classify a clothing item to any of the 10 categories. Each image is of $28X28$ grayscale pixels, i.e. there are total of 784 pixels in an image. Each pixel is of value from 0 to 255 representing from white to gradual change to black.\n",
        "\n",
        "![](https://github.com/jarusgnuj/ai-ml-wksh/blob/43a0d083c059e7f93023d8f29af87c9682bf02cf/data/image_classification/figures/fashion-mnist-sprite.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOMZCQfqjZQy",
        "colab_type": "text"
      },
      "source": [
        "We can download the fashion MNIST dataset from the tensorflow dataset api. For this we need to first install libraries for tensorflow dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjqkwSXxhWx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U tensorflow_datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVgt91mXi6or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as input_data\n",
        "import tensorflow as tf\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onofI-Yo2j0D",
        "colab_type": "text"
      },
      "source": [
        "We import training and testing data. We train a Neural Network to learn to classify images in the training data and then we use the test data to verify how well the neural network has learnt to classify the images.\n",
        "\n",
        "![](https://github.com/jarusgnuj/ai-ml-wksh/blob/master/data/image_classification/figures/train-test.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRBA1AmVk1ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Fashion MNIST\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ_r2f45nnt0",
        "colab_type": "text"
      },
      "source": [
        "There are 60k images in training set of $28X28$ pixels and similarly sized 10k images in the test set. The size part will be bit more clear once we view an example image. Actually, lets see one image from the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEqw9o5muW0g",
        "colab_type": "text"
      },
      "source": [
        "The fashion mnist data has 10 categories with value [0, 9]. The different images used are *T-shirt/top, Trouser, Pullover, Dress, Coat, \n",
        " Sandal,  Shirt,   Sneaker,  Bag*,  and  *Ankle boot*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHC5MCaVY9dB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv6V_E4elJPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(x_train[0], cmap=plt.cm.binary)\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.xlabel(class_names[y_train[0]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPgrlAqzpY-U",
        "colab_type": "text"
      },
      "source": [
        "The colour bar shows the pixel value and its gradient. The value for each pixel in the image is from 0 to 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukxBL_Agod01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train[0][23][10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBneJq_WsiAO",
        "colab_type": "text"
      },
      "source": [
        "For a neural network to work efficiently, it is always a good practice to normalise the data between the value [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz5NRRT3qekq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtOMfhlnszBL",
        "colab_type": "text"
      },
      "source": [
        "Let's plot a normalised image data. We will notice the value change in the colour bar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHDB_YUxtCm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(x_train[0], cmap=plt.cm.binary)\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjri7UA2tD_D",
        "colab_type": "code",
        "outputId": "8579f85f-7344-4846-f89c-9afff7186c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ea_GgI8vOxC",
        "colab_type": "text"
      },
      "source": [
        "Let's display few of the images from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe8ZeGT3t6NV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))           \n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu_3AjGnkPXF",
        "colab_type": "text"
      },
      "source": [
        "## Excercise 1: Load similar data points\n",
        "\n",
        "Change the label names in data1, and data2 below to compare two images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSNWPlFWe8se",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exercise 1: Load similar looking data points\n",
        "\n",
        "data1 = \"Sandal\"\n",
        "data2 = \"Coat\"\n",
        "v1 =-1\n",
        "v2 =-1\n",
        "while True:\n",
        "  rnd =np.random.randint(60000)\n",
        "  for im in range (rnd, 60000):\n",
        "    if class_names[y_train[im]] ==data1:\n",
        "      v1 = im\n",
        "    if class_names[y_train[im]] ==data2:\n",
        "      v2 = im\n",
        "    if v1!=-1 and v2!=-1:\n",
        "      break\n",
        "  if v1!=-1 and v2!=-1:\n",
        "    break;\n",
        "plt.figure(figsize=(5,5))\n",
        "for i in range(2):\n",
        "    plt.subplot(1,2,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    if i ==0:\n",
        "      plt.imshow(x_train[v1], cmap=plt.cm.binary)\n",
        "      plt.xlabel(class_names[y_train[v1]])\n",
        "    else:\n",
        "      plt.imshow(x_train[v2], cmap=plt.cm.binary)\n",
        "      plt.xlabel(class_names[y_train[v2]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK2FQqNI4ijl",
        "colab_type": "text"
      },
      "source": [
        "#The neural network\n",
        "\n",
        "We will still use the same 3 layered neural network, the only thing we change is the number of inputs (which now is 784) and the number of hidden neurons to 128.\n",
        "\n",
        "![](https://github.com/jarusgnuj/ai-ml-wksh/blob/master/data/image_classification/figures/feed-forward-fmnist-for-keras.jpg?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj89EGCvzw8B",
        "colab_type": "text"
      },
      "source": [
        "# Define Model\n",
        "\n",
        "Models in Keras are defined by stacking layers. Layers in Keras can be a simple feed forward network to complex convolutions layers. A layer takes in a certain number of input and gives a certain number of output. We stack layers in a sequential container. In Keras we need to provide the input dimension for the first layer, the input dimension of following layers are inferrred automatically. We will use feed forward network, which is defined as *Dense* layer in Keras. The only thing we need to be aware is that we are converting the 28x28 pixels image to a 1D (flattened) 784 pixel values. This is done using a *Flatten* layer as a first layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwddFH5n0PSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "#     tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10,  activation=tf.nn.softmax)\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdoLlEub1Q24",
        "colab_type": "text"
      },
      "source": [
        "#Compile Model\n",
        "\n",
        "Now that the model is defined, we can compile it.\n",
        "\n",
        "\n",
        "When compiling, we must specify some additional properties required when training the network. Remember training a network means finding the best set of weights to make predictions for this problem.\n",
        "\n",
        "We must specify the *loss function* to use to evaluate a set of weights, the *optimizer* used to search through different weights for the network and any *optional metrics* we would like to collect and report during training.\n",
        "\n",
        "In this case, we will use logarithmic loss, which for a multi class classification problem is defined in Keras as “categorical_crossentropy“. We will also use the efficient gradient descent algorithm “adam”. \n",
        "Finally, because it is a classification problem, we will collect and report the classification accuracy as the metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgmmNb1K2E63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfBxmPJ02Pev",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Train Model\n",
        "\n",
        "We have defined our model and compiled it ready for efficient computation.\n",
        "\n",
        "Now it is time to execute the model on some data.\n",
        "\n",
        "We can *train or fit* our model on our loaded data by calling the *fit()* function on the model.\n",
        "\n",
        "The training process will run for a fixed number of iterations through the dataset called *epochs*, that we must specify using the *epochs* argument. We can also set the number of instances that are evaluated before a weight update in the network is performed, called the batch size and set using the batch_size argument.\n",
        "\n",
        "For this problem, we will run for a small number of iterations (10) and use a relatively small batch size of 25. Again, these can be chosen experimentally by trial and error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hre4BvI2pLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=25, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EILbulkLCdKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kADaYq-3HboI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Plot a random sample of 15 test images, their predicted labels and ground truth\n",
        "y_hat = model.predict(x_test)\n",
        "figure = plt.figure(figsize=(20, 8))\n",
        "for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n",
        "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
        "    # Display each image\n",
        "    ax.imshow(np.squeeze(x_test[index]), cmap=plt.cm.binary)\n",
        "    predict_index = np.argmax(y_hat[index])\n",
        "    true_index = y_test[index]\n",
        "    # Set the title for each image\n",
        "    ax.set_title(\"{} ({})\".format(class_names[predict_index], \n",
        "                                  class_names[true_index]),\n",
        "                                  color=(\"green\" if predict_index == true_index else \"red\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TOtF2WBJOMp",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8u6e-XXJOxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "confusion = confusion_matrix(y_test, np.argmax(y_hat,axis=1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPzxGBbvJRec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_confusion_matrix(confusion, \n",
        "                      normalize    = False,\n",
        "                      target_names = class_names,\n",
        "                      title        = \"Confusion Matrix\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNw_6HHBkzrd",
        "colab_type": "text"
      },
      "source": [
        "## Excercise 2: Tune Model\n",
        "\n",
        "Go back to **Train Models** and change:\n",
        "\n",
        " - batch_size: To both lower and higher number. Notice change in training speed. Also is there change in accuracy?\n",
        " - epochs: to a higher number. Is there any change in accuracy?\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdmaSd2jJ3-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}